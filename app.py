import random
import gradio as gr
import json
import requests
import logging
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# èŠå¤©åŠŸèƒ½é…ç½®
from ConfigManager import ConfigManager
conf = ConfigManager()
SILICONFLOW_API_KEY = conf.get_text_model_config()["api_key"]
SILICONFLOW_API_URL = "https://api.siliconflow.cn/v1/chat/completions"
MODEL_NAME = conf.get_text_model_config()["name"]

def LLM_response(message, history):
    """æµå¼ç”Ÿæˆå“åº”çš„ç”Ÿæˆå™¨å‡½æ•°"""
    # æ„å»ºæ¶ˆæ¯å†å²
    messages = []
    for human, assistant in history:
        if (human):
            messages.append({"role": "user", "content": human})
        if (assistant):
            messages.append({"role": "assistant", "content": assistant})
    messages.append({"role": "user", "content": message})

    headers = {
        "Authorization": f"Bearer {SILICONFLOW_API_KEY}",
        "Content-Type": "application/json",
    }
    
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "temperature": 0.7,
        "max_tokens": 1024,
        "stream": True
    }
    logging.info(SILICONFLOW_API_URL)
    logging.info(SILICONFLOW_API_KEY)
    logging.info(MODEL_NAME)
    logging.info("LLMå·²è½¬å‘æäº¤")
    logging.info(str(messages))

    try:
        with requests.post(
            SILICONFLOW_API_URL,
            headers=headers,
            json=payload,
            stream=True
        ) as response:
            if response.status_code != 200:
                yield f"APIé”™è¯¯: {response.status_code} - {response.text}"
                return
                
            accumulated_text = ""
            for chunk in response.iter_lines():
                if chunk:
                    decoded_chunk = chunk.decode('utf-8')
                    if decoded_chunk.startswith("data:"):
                        json_data = decoded_chunk[5:].strip()
                        if json_data == "[DONE]":
                            return
                        # è§£ææ€è€ƒå†…å®¹
                        try:
                            data = json.loads(json_data)
                            choices = data.get("choices", [])
                            if choices:
                                delta = choices[0].get("delta", {})
                                content = delta.get("reasoning_content", "")
                                if content:
                                    accumulated_text += content
                                    yield accumulated_text
                        except Exception as e:
                            # è§£æé”™è¯¯æ—¶ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªchunk
                            pass
                        
                        # è§£æå›å¤å†…å®¹
                        try:
                            data = json.loads(json_data)
                            choices = data.get("choices", [])
                            if choices:
                                delta = choices[0].get("delta", {})
                                content = delta.get("content", "")
                                if content:
                                    accumulated_text += content
                                    yield accumulated_text
                        except Exception as e:
                            # è§£æé”™è¯¯æ—¶ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªchunk
                            continue
    except Exception as e:
        yield f"è¯·æ±‚å¤±è´¥: {str(e)}"

# å…³äºä¸¥å°å¸Œçš„HTMLå†…å®¹
from YanxxPage import Yanxx_Page
def yan_page_html():
    return Yanxx_Page()

# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="æ™ºèƒ½åŠ©æ‰‹åº”ç”¨", css=".panel {border-radius: 10px; padding: 15px;}") as demo:
    # çŠ¶æ€å˜é‡
    username = gr.State("cxxdgc")
    current_page = gr.State(0)
    chat_history = gr.State([])
    
    # æ•´ä¸ªåº”ç”¨å¸ƒå±€ - ä½¿ç”¨è¡Œå¸ƒå±€å¹¶æŒ‡å®šæ¯”ä¾‹
    with gr.Row():
        # å·¦ä¾§å¯¼èˆªæ  - è®¾ç½®ä¸º1/5å®½åº¦
        with gr.Column(scale=1, min_width=200):
            with gr.Column(elem_classes="panel", variant="panel"):
                gr.Markdown("### å¯¼èˆªèœå•")
                home_btn = gr.Button("é¦–é¡µ", size="sm", variant="primary")
                feature1_btn = gr.Button("è‡ªåŠ¨æ‰¹æ³¨", size="sm")
                feature2_btn = gr.Button("è‡ªåŠ¨æ‘˜æŠ„", size="sm")
                yan_btn = gr.Button("å…³äºä¸¥å°å¸Œ", size="sm")
                settings_btn = gr.Button("è®¾ç½®", size="sm")
                
                gr.Markdown("---")
                gr.Markdown(f"**ç”¨æˆ·**: cxxdgc")
                logout_btn = gr.Button("é€€å‡ºç™»å½•", size="sm", variant="stop")
        
        # å³ä¾§å†…å®¹åŒº - è®¾ç½®ä¸º4/5å®½åº¦
        with gr.Column(scale=4):
            # é¡µé¢å®¹å™¨
            with gr.Column(visible=True, elem_classes="panel") as home_container:
                # èŠå¤©ç•Œé¢
                gr.Markdown("## æ™ºèƒ½åŠ©æ‰‹èŠå¤©ç•Œé¢")
                gr.Markdown("ä¸AIåŠ©æ‰‹äº¤æµï¼Œæé—®é—®é¢˜æˆ–è¿›è¡Œå¯¹è¯")
                
                chatbot = gr.Chatbot(height=500, label="AIåŠ©æ‰‹")
                msg = gr.Textbox(label="è¯·è¾“å…¥æ¶ˆæ¯", placeholder="è¾“å…¥æ‚¨çš„é—®é¢˜åæŒ‰Enterå‘é€...")
                with gr.Row():
                    clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯")
                    file_upload = gr.UploadButton("ğŸ“ ä¸Šä¼ æ–‡ä»¶", file_types=["text", ".json", ".pdf", ".docx"])
                file_output = gr.Markdown()
            
            # è‡ªåŠ¨æ‰¹æ³¨é¡µé¢
            with gr.Column(visible=False, elem_classes="panel") as feature1_container:
                gr.Markdown("## è‡ªåŠ¨æ‰¹æ³¨åŠŸèƒ½")
                gr.Markdown("ä¸Šä¼ æ–‡æœ¬æˆ–æ–‡æ¡£ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ·»åŠ æ‰¹æ³¨")
                
                with gr.Row():
                    text_input = gr.Textbox(label="è¾“å…¥æ–‡æœ¬", lines=10, placeholder="åœ¨æ­¤è¾“å…¥è¦æ‰¹æ³¨çš„æ–‡æœ¬...")
                    file_input = gr.File(label="æˆ–ä¸Šä¼ æ–‡æ¡£", file_types=[".txt", ".pdf", ".docx"])
                
                generate_btn = gr.Button("å¼€å§‹æ‰¹æ³¨")
                output_area = gr.Textbox(label="æ‰¹æ³¨ç»“æœ", interactive=False, lines=15)
            
            # è‡ªåŠ¨æ‘˜æŠ„é¡µé¢
            with gr.Column(visible=False, elem_classes="panel") as feature2_container:
                gr.Markdown("## è‡ªåŠ¨æ‘˜æŠ„åŠŸèƒ½")
                gr.Markdown("ä¸Šä¼ æ–‡æ¡£ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æå–å…³é”®å†…å®¹å’Œæ‘˜è¦")
                
                file_input_f2 = gr.File(label="ä¸Šä¼ æ–‡æ¡£", file_types=[".pdf", ".docx", ".txt"])
                extract_btn = gr.Button("å¼€å§‹æå–")
                
                with gr.Row():
                    key_points = gr.Textbox(label="å…³é”®è¦ç‚¹", interactive=False, lines=10)
                    summary = gr.Textbox(label="æ–‡ç« æ‘˜è¦", interactive=False, lines=10)
            
            # å…³äºä¸¥å°å¸Œé¡µé¢
            with gr.Column(visible=False, elem_classes="panel") as yan_container:
                gr.HTML(yan_page_html())
            
            # è®¾ç½®é¡µé¢
            with gr.Column(visible=False, elem_classes="panel") as settings_container:
                gr.Markdown("## ç³»ç»Ÿè®¾ç½®")
                
                with gr.Row():
                    with gr.Column(min_width=300):
                        gr.Markdown("### ç•Œé¢è®¾ç½®")
                        dark_mode = gr.Checkbox(label="æ·±è‰²æ¨¡å¼")
                        notification = gr.Checkbox(label="å¯ç”¨é€šçŸ¥")
                    
                    with gr.Column(min_width=300):
                        gr.Markdown("### AIè®¾ç½®")
                        ai_temperature = gr.Slider(minimum=0, maximum=1, step=0.1, value=0.7, label="åˆ›é€ åŠ›")
                        ai_max_tokens = gr.Slider(minimum=100, maximum=2000, step=100, value=1024, label="æœ€å¤§ç”Ÿæˆé•¿åº¦")
                
                save_btn = gr.Button("ä¿å­˜è®¾ç½®")
                status = gr.Markdown("")
    
    # é¡µé¢åˆ‡æ¢å‡½æ•°
    def show_page(page_idx):
        return [gr.update(visible=page_idx==i) for i in range(5)]
    
    # èŠå¤©é¡µé¢çš„äº‹ä»¶
    # æ·»åŠ ç¼ºå¤±çš„èŠå¤©å“åº”å‡½æ•°
    def respond(message, history):
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶è¿”å›AIçš„æµå¼å“åº”"""
        # åˆå§‹åŒ–AIå›å¤ä¸ºç©º
        history = history.copy()  # åˆ›å»ºå‰¯æœ¬é¿å…ç›´æ¥ä¿®æ”¹åŸå§‹çŠ¶æ€
        history.append((message, ""))  # æ·»åŠ æ–°æ¶ˆæ¯ï¼ˆAIå›å¤ä¸ºç©ºï¼‰
        
        # ç¬¬ä¸€æ¬¡æ›´æ–°ï¼šæ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯å’Œç©ºç™½çš„AIå›å¤
        yield "", history, history
        
        full_response = ""
        # è°ƒç”¨LLM_responseç”Ÿæˆå™¨è·å–æµå¼å“åº”
        for token in LLM_response(message, history[:-1]):  # ä¼ å…¥å½“å‰æ¶ˆæ¯å‰çš„å†å²
            full_response = token
            # æ›´æ–°æœ€åä¸€æ¡AIå›å¤å†…å®¹
            history[-1] = (message, full_response)
            yield "", history, history

    
    msg.submit(
        respond,
        inputs=[msg, chat_history],  # è¾“å…¥ï¼šæ¶ˆæ¯å†…å®¹ï¼ŒèŠå¤©å†å²
        outputs=[msg, chatbot, chat_history]  # è¾“å‡ºï¼šæ¸…ç©ºè¾“å…¥æ¡†ï¼Œæ›´æ–°èŠå¤©æ¡†ï¼Œæ›´æ–°å†å²çŠ¶æ€
    )
    
    clear_btn.click(
        lambda: [[], []],
        outputs=[chatbot, chat_history]
    )
    
    file_upload.upload(
        lambda file: f"å·²æ”¶åˆ°æ–‡ä»¶: {file.name}",
        inputs=[file_upload],
        outputs=file_output
    )
    
    # æ‰¹æ³¨é¡µé¢çš„äº‹ä»¶
    generate_btn.click(
        lambda text, file: "è¿™æ˜¯ç”Ÿæˆçš„æ‰¹æ³¨ç¤ºä¾‹ï¼š\n\n- ç¬¬ä¸€ç‚¹æ‰¹æ³¨\n- ç¬¬äºŒç‚¹æ‰¹æ³¨\n- ç¬¬ä¸‰ç‚¹æ‰¹æ³¨",
        inputs=[text_input, file_input],
        outputs=output_area
    )
    
    # æ‘˜æŠ„é¡µé¢çš„äº‹ä»¶
    extract_btn.click(
        lambda file: ("å…³é”®è¦ç‚¹ï¼š\n1. è¦ç‚¹ä¸€\n2. è¦ç‚¹äºŒ\n3. è¦ç‚¹ä¸‰", "æ–‡ç« æ‘˜è¦ï¼š\næœ¬æ–‡ä¸»è¦è®¨è®ºäº†..."),
        inputs=[file_input_f2],
        outputs=[key_points, summary]
    )
    
    # è®¾ç½®é¡µé¢çš„äº‹ä»¶
    save_btn.click(
        lambda dark, notify, temp, tokens: "è®¾ç½®å·²ä¿å­˜æˆåŠŸï¼",
        inputs=[dark_mode, notification, ai_temperature, ai_max_tokens],
        outputs=status
    )
    
    # å¯¼èˆªæŒ‰é’®äº‹ä»¶
    home_btn.click(lambda: [0, *show_page(0)], outputs=[current_page, home_container, feature1_container, feature2_container, yan_container, settings_container])
    feature1_btn.click(lambda: [1, *show_page(1)], outputs=[current_page, home_container, feature1_container, feature2_container, yan_container, settings_container])
    feature2_btn.click(lambda: [2, *show_page(2)], outputs=[current_page, home_container, feature1_container, feature2_container, yan_container, settings_container])
    yan_btn.click(lambda: [3, *show_page(3)], outputs=[current_page, home_container, feature1_container, feature2_container, yan_container, settings_container])
    settings_btn.click(lambda: [4, *show_page(4)], outputs=[current_page, home_container, feature1_container, feature2_container, yan_container, settings_container])
    
    # ç™»å‡ºäº‹ä»¶
    
    # åˆå§‹åŠ è½½æ˜¾ç¤ºé¦–é¡µ
    demo.load(lambda: [gr.update(visible=True), gr.update(visible=False), gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)],
              outputs=[home_container, feature1_container, feature2_container, yan_container, settings_container])

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    demo.launch()